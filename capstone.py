# -*- coding: utf-8 -*-
"""CAPSTONE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10zdVwuCfMhDn9maLkjWv8zE0xCPlAsvC
"""

from google.colab import files
uploaded=files.upload()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
df=pd.read_csv("capstonetrain.csv")
test_df=pd.read_csv("capstone_test.csv")

test_df

df

df.info()

df.isnull().sum()

df['iswomen'] = ['Women' if 'Women' in x else 'Men' for x in df['title']]

test_df.info()

df['maincateg'].fillna(df['iswomen'],inplace=True)
test_df['maincateg'].fillna(df['iswomen'],inplace=True)

df.info()

plt.figure(figsize=(12,10))
sns.heatmap(df.isnull())
plt.title("Heatmap of Missing Values", fontsize=18)
plt.show()

plt.figure(figsize=(12,10))
sns.heatmap(test_df.isnull())
plt.title("Heatmap of Missing Values", fontsize=18)
plt.show()

"""**Removing rows with high number of nan values**"""

df1=df.dropna(thresh=14,axis=0)

df1.shape

plt.figure(figsize=(15,12))
sns.heatmap(df1.isnull())

df1.isnull().sum()

df1[df1['star_2f']+df1['star_1f']+df1['star_3f']+df1['star_4f']+df1['star_5f']==0]

df1[df1['star_2f']+df1['star_1f']+df1['star_3f']+df1['star_4f']+df1['star_5f']==0]=df1[df1['star_1f']+df1['star_2f']+df1['star_3f']+df1['star_4f']+df1['star_5f']==0].replace(0,np.nan)

df1.isnull().sum()

df1['fulfilled1']=df1['fulfilled1'].replace(np.nan,0)



"""MISSING VALUES IMPUTATION"""

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
#from sklearn.impute import KNNImputer
# from sklearn.linear_model import LinearRegression
# lr=LinearRegression()
mice_cols = ['Rating','actprice1','norating1','noreviews1','star_5f','star_4f','star_3f','star_2f','star_1f']

# Define MICE Imputer and fill missing values
imputer = IterativeImputer()
df1[mice_cols]=imputer.fit_transform(df1[mice_cols])
test_df[mice_cols]=imputer.transform(test_df[mice_cols])

test_df.info()

df1.shape

df1['review%']=df1['noreviews1']/df1['norating1']*100

sns.set_theme(style="whitegrid")
plt.figure(figsize=(12,8))
sns.scatterplot(data=df1,x='norating1',y='review%',hue='platform')

df1.loc[df1['review%']>100]                                   #FOR REMOVING OUTLIERS
df1.drop(df1.index[df1['review%'] >100], inplace=True)

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.boxplot(data=df1,x='Rating')

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.boxplot(data=df,x='price1')

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.boxplot(data=df,x='actprice1')

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.boxplot(data=df1,x='norating1')

df[df['norating1']>75000].shape

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.boxplot(data=df1,x='noreviews1')

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.countplot(data=df1,x='fulfilled1',hue='fulfilled1')

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.scatterplot(data=df1,x='Rating',y='price1',hue='fulfilled1')

df1["Offer %"] = df1["Offer %"].astype(str).str.replace("%", "", regex=False)

df1['Offer %'] = df1['Offer %'].astype(float)

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.countplot(data=df1,x='Rating',hue='maincateg')

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.countplot(data=df,x='Rating',hue='fulfilled1')

plt.figure(figsize=(15,12))
sns.set_theme(style="whitegrid")
sns.scatterplot(data=df1,x='actprice1',y='price1',hue='fulfilled1')

df[df['actprice1']<df['price1']]

df1[['price1','actprice1']] = df1[['actprice1','price1']].where(df1['actprice1']<df1['price1'], df1[['price1','actprice1']].values)

df2=df1.drop(columns=['title','maincateg','iswomen','platform'])

df2.corr()

input_cols=['Rating', 'actprice1','norating1', 'noreviews1',
       'fulfilled1','star_5f', 'star_4f', 'star_3f', 'star_2f', 'star_1f',]
target_col1='Offer %'
target_col2='price1'

from sklearn.preprocessing import MinMaxScaler
scaler1 = MinMaxScaler()
df1[input_cols]=scaler1.fit_transform(df1[input_cols])
test_df[input_cols]=scaler1.transform((test_df[input_cols]))
X_scaled1=df1[input_cols]
X_test_scaled1=test_df[input_cols]
X_scaled1

y1=df1['Offer %']
y2=df1['price1']

from sklearn.model_selection import train_test_split
X_train1, X_val1, y_train1, y_val1 = train_test_split( X_scaled1,y1, test_size=0.2, random_state=42)#for offer %
# for price
X_train2, X_val2, y_train2, y_val2 = train_test_split( X_scaled1,y2, test_size=0.2, random_state=42)

from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor,XGBRFRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
modeld=DecisionTreeRegressor()
modelr=RandomForestRegressor()
modelxgb = XGBRegressor()

def train_and_evaluate(model,X_train,y_train, X_val,y_val, **params):
    model.fit(X_train, y_train)
    train_rmse =mean_squared_error(model.predict(X_train), y_train,squared=False)
    val_rmse = mean_squared_error(model.predict(X_val), y_val,squared=False)
    r2score= r2_score( y_val,model.predict(X_val))
    return model, train_rmse, val_rmse,r2score

train_and_evaluate(modeld,X_train2,y_train2, X_val2,y_val2)

train_and_evaluate(modelr,X_train2,y_train2, X_val2,y_val2)

train_and_evaluate(modelxgb,X_train2,y_train2, X_val2,y_val2)

def train_and_evaluaterf(X_train,y_train, X_val,y_val, **params):
    model=RandomForestRegressor(n_jobs=-1,random_state=42,**params)
    model.fit(X_train, y_train)
    train_rmse =mean_squared_error(model.predict(X_train), y_train,squared=False)
    val_rmse = mean_squared_error(model.predict(X_val), y_val,squared=False)
    r2score= r2_score( y_val,model.predict(X_val))
    print(r2score)
    print(train_rmse)
    print(val_rmse)

train_and_evaluaterf(X_train2,y_train2, X_val2,y_val2,n_estimators=50)